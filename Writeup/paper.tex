\documentclass{sig-alternate-05-2015}

\usepackage{graphicx}

\def\sharedaffiliation{%
\end{tabular}
\begin{tabular}{c}}

\begin{document}
	
	% Copyright
	\setcopyright{acmcopyright}
	%\setcopyright{acmlicensed}
	%\setcopyright{rightsretained}
	%\setcopyright{usgov}
	%\setcopyright{usgovmixed}
	%\setcopyright{cagov}
	%\setcopyright{cagovmixed}
	
	
	% DOI
	\doi{n/a}
	
	% ISBN
	\isbn{n/a}

\date{\today}
\title{\ttlfnt{Comparing the performance of websites and their content distribution networks}}
\author{
	\begin{tabular}{c}
		% 1st. author
		Jacques Heunis \\
		\affaddr{University of Cape Town}\\
		\email{hnsjac003@myuct.ac.za}
	\end{tabular}%
	\begin{tabular}{c}
		% 2nd. author
		Brian McGeorge \\
		\affaddr{University of Cape Town}\\
		\email{mcgbri004@myuct.ac.za}
	\end{tabular} 
}

\maketitle

\begin{abstract}
\end{abstract}

\section{Introduction}\label{sec:intro}
In the modern internet, 65\% of web traffic is handled by just 10 organisations \cite{Gehlen2012}. These organisations have to serve tremendous amounts of data to a large user base across the globe. Vast Content Delivery Networks (CDN) and data centres are therefore required to serve up all this content. Approximately 90\% of Google's traffic and over 50\% of Level3 and Limelight's traffic is from video content alone \cite{Gehlen2012}. Labovitz \textit{et al.} \cite{Labovitz:2010:IIT:2043164.1851194} suggests that videos account for $25-40\%$ of all HTTP traffic. 

Of the video streaming services on the internet, YouTube is most popular with over a billion users \cite{youtubeStats}. Everyday, YouTube generates billions of views with people watching hundreds of million of hours of content \cite{youtubeStats}. With new content constantly getting generated around the world, caching strategies are required so that this content can be served up at a high throughput from as close as possible to the user. ISPs play a critical role in this through their peering policies and by providing their own CDNs for various content \cite{Labovitz:2010:IIT:2043164.1851194}.

Our aim in this paper is to investigate the performance of the CDN's that serve this content. We will examine different streaming services across a variety of South African Internet Service Providers (ISP) to examine how traffic is routed and where it comes from. In addition, we will also examine the caching behaviour of YouTube, which has local caches in South Africa. We have developed a tool which automates many of the aforementioned measurements. It can take a list of URLs to content on a streaming service and record various performance metrics regarding how the content is delivered to the end-user.

Section \ref{sec:related} will examine related work in measuring the performance of streaming services and studies which investigate the behaviour of CDNs for multimedia streaming services. Section \ref{sec:method} describes the tool that we developed and details the steps we followed in using it to capture our results. Section \ref{sec:results} presents the results and a discussion thereof.



\section{Related Work}\label{sec:related}
% Relevant work that has been done
Uncovering the Big Players of the Web\\
Dissecting Video Server Selection Strategies
in the YouTube CDN\\
YouTube traffic dynamics and its interplay with a tier-1 ISP: an ISP perspective\\
When YouTube Does not Work - Analysis of QoE-Relevant Degradation in Google CDN Traffic\\
Internet Inter-Domain Traffic\\
YouTube Traffic Characterization: A View From the Edge\\


% TODOs:
% 	- add a section on the tool, what it does and how it tries to ensure accuracy and repeatability in our dynamic environment (throughput and ping tests beforehand, repeating each run 3 times, re-try logic to make the code robust etc. etc. Just sell it!)
% 	- (Sub?)Section on the data we collect and why this information is useful for our study
\section{Method}\label{sec:method}
\subsection{Measurement and tools}
To measure the performance of CDNs, we have created a tool to automatically capture various quantitative and qualitative performance metrics when given a list of URLs to online video or audio content. In order to compare the performance of CDNs to that of the websites that present the content, we measure 2 primary quantitative metrics: Ping or Round-trip-time and the number of hops required to reach the server. We also measure the throughput to the CDN. To gain further insight into the potential causes for variances in performance, we also take note of the location and owner of the web page and CDN IPs.

Our tool is written using Python 3, but makes use of a number of third-party tools and services. It makes use of the youtube-dl\footnote{youtube-dl: available at https://rg3.github.io/youtube-dl/} tool to download multimedia content (which is used to measure bandwidth, as detailed below), and uses tcpdump to passively capture network traffic (on Windows we use WinDump which is a Windows port of tcpdump, but for the purposes of this report we will refer to tcpdump). The ipinfo.io service\footnote{ipinfo: available at http://ipinfo.io/} is used to gather information about the registered owners of the website and CDN IP addresses.

For each input URL we run youtube-dl and ask that it simply return the URL of the actual content and exit. Both URLs are resolved to IP addresses and stored for later measurement. We then run tcpdump, specifying that it will terminate after 3000 packets have been received, and then run youtube-dl again. This time we let youtube-dl actually download the media file, allowing tcpdump to the required 3000 packets and then terminate. At this point we can kill the youtube-dl process and just consider its output. First, we look at the last line of output from youtube-dl in order to get the throughput that the content was transmitted at. This does mean that we rely on youtube-dl's measurements being accurate, but previous attempts to measure throughput ourselves proved inaccurate as youtube-dl does some work before downloading (for example to get the CDN URL from the webpage).

Next we go through every packet that tcpdump captured and find the IP that sent us the most packets. We consider that to be the IP that the content actually came from, as long as more than one third of the captured packets came from that IP. Now we have an IP for the website, the CDN, and the actual content, and we run ping and traceroute, as well as querying ipinfo.io for all three of these.

In order to reduce the chance of our results being affected by other applications that might be using the network, we first listen to the existing traffic on the network when the tool first starts up. If there is more than 100KB/s of incoming traffic or more than 30KB/s of outgoing traffic, we prompt the user to reduce network traffic and do not proceed with the test. This gives our results greater accuracy and repeatability as it prevents us from running the experiment when there is already high-network usage, which would skew the data.

In order to further improve the accuracy of our results, we run each test 3 times for each input URL. This prevents a short-running network-intensive process from executing only during one test and leading us to believe that one particular website or piece of content is received significantly more slowly than the others.

\subsection{Sources of multimedia content}
As mentioned in Section \ref{sec:intro}, Youtube is one of the most popular video streaming services on the internet. Since this is not a study of Youtube specifically, we need to gather data on a number of other multimedia streaming services as well. We decided to also gather data about the popular music sharing service Soundcloud, as well as the popular live video streaming platform Twitch.tv. Note that our analysis is restricted to on-demand multimedia streaming and we do not consider the performance of live streaming services on Youtube or Twitch.tv. Note also that we did not include Netflix in our evaluation. While Netflix does constitute a large portion of internet video streaming traffic in the US, it is far less popular in South Africa and so its performance is of less importance here.

Of particular interest is the effect of caching on the performance of Youtube videos. It is widely known that there are Google caches in South Africa and that local ISPs have their own caches. For this reason we specifically included performance evaluations for Youtube videos that are unpopular or have very few views. To find such videos, we manually looked through the ``unknownvideos'' section of Reddit\footnote{``/r/unknownvideos - Watch something new'', available at https://www.reddit.com/r/unknownvideos}.

\section{Data?}\label{sec:data} % How is this different from results AND method? >.>
\section{Results}\label{sec:results}
\section{Future Work}\label{sec:futurework}


\pagebreak

\small
\bibliographystyle{abbrv}
\bibliography{paper}  % sigproc.bib is the name of the Bibliography in this case


\end{document}
